# roc
tpr(真阳率):所有预测和真实都是1的样本数量/所有真实标签为1的样本数量
fpr(假阳率):所有预测为1真实为0的样本数量/所有真实为0的样本数量
roc曲线的

# auc
**auc的物理含义代表roc曲线的曲线下面积**
> 从Mann–Whitney U statistic的角度来解释，AUC就是从所有1样本中随机选取一个样本， 从所有0样本中随机选取一个样本，然后根据你的分类器对两个随机样本进行预测，把1样本预测为1的概率为p1，把0样本预测为1的概率为p0，p1>p0的概率就等于AUC。所以AUC反应的是分类器对样本的排序能力。

auc可以通过如下方式计算:
$$
auc=\frac{(\sum\limits_{i \in (label=1)}rank(i) )-n1*(n1+1)/2}{n_0*n_1}
$$
其中$rank(i)$代表正样本i在所有正负样本预测概率值中的序。
可以发现,$n_0,n_1$都是固定值，只有$rank(i)$和最终的auc分值有关系。所以可以确定，**auc度量的是分类器对样本的排序能力**。

**auc的另一种计算方式**:
$$
auc=\frac{\sum\limits_{i in (label=1)} \text{预测概率小于等于当前正样本的负样本个数}}{n_0*n_1}
$$

# gauc
$$
gauc=\frac{\sum\limits_{i=1}^{n}w_i*AUC_i}{\sum\limits_{i=1}^{n}w_i}
$$
其中$n$代表用户总数，$w_i$既可以是该用户点击总次数，也可以是曝光总次数

## auc存在问题
假设存在两个用户甲和乙,其中甲两个样本，乙三个样本,以及两个打分模型A、B。
模型A对五个样本的打分顺序从小到大为:甲-,甲+,乙-,甲+,乙+.
模型B对五个样本的打分顺序从小到大为:甲-,甲+,甲+,乙-,乙+
则可以计算出模型A的auc为0.833，模型B的auc为0.667。
根据auc值模型A应该优于模型B,但在两个模型上，甲乙两个用户正样本分值都比负样本高,实际上看,两个模型效果应该一致。
可以发现,auc分值会受到不同用户之间各自打分偏差影响，例如即使两个用户正样本都比负样本分值高，但一个用户所有样本打分都高于另一个用户，可能auc也会很低。
