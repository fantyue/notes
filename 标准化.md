## BatchNorm
$$
\text{Input:B}=\{x_{1...m}\};
\gamma,\beta\text{(parameters to be learned)} \\
~\\
\text{Output:}\{y_i=BN_{\gamma\beta(x_i)}\} \\
~\\
\mu_B \leftarrow \frac{1}{m} \sum \limits_{i=1}^m x_i \\
~\\
\alpha_B^2 \leftarrow \frac{1}{m} \sum\limits\limits_{i=1}^m(x_i-\mu_B)^2 \\
~\\
\tilde{x_i} \leftarrow \frac{x_i-\mu_B}{\sqrt{\alpha_B^2+\epsilon}} \\
~\\
y_i \leftarrow \gamma \tilde{x_i} + \beta
$$
>其中$\gamma,\beta$是可训练参数。  
>把一个batch的数据维度记为$[N,H,W,C]$，其中$N$代表batch_size，$H,W$代表行列长度，$C$代表通道数。
> 均值:把一个batch内，每个通道的数字单独加和，


## WeightNorm

## InstanceNorm

## LayerNorm

## GroupNorm

## PositionalNorm

## ConditionalBatchN