## 1.Sigmoid
$$
\alpha(x)=\frac{1}{1+e^{-x}}
$$

> 假设一个全连接网络最后一层激活函数为sigmoid,对于最后一层的网络权重$w^L$
> loss函数对$w^L$的导数为:
> $$\frac{\alpha L}{\alpha w^L}=\frac{\alpha L}{\alpha^L}\frac{\alpha^L}{z^L}\frac{z^L}{w^L}$$
> $$\frac{\alpha^L}{z^L}=\sigma^\prime(w * a^{L-1}+b)$$
> $$\sigma^\prime(x)=\sigma(x)(1-\sigma(x))=\frac{e^{-x}}{(e^{-x}+1)^2}$$
> 当输入的x绝对值很大时,$\sigma^\prime(x)$趋向于0;当输入的x绝对值很小时,$\sigma^\prime(x)$最大也只能达到0.25,在网络层数加深后,链式法则梯度反向传播，容易发生梯度消失,且层数越前越容易发生这种情况。